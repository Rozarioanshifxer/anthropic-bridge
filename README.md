# Anthropic Bridge - OpenRouter Proxy Service

**Translation Service**: Anthropic API format â†’ OpenAI format â†’ OpenRouter

Convert Anthropic's message format to OpenAI's chat completions format and route to OpenRouter for multi-model access.

## ğŸš€ Deployment Options

### âœ… LXC Container (Proxmox) - RECOMMENDED FOR PRODUCTION

**Status**: âœ… ACTIVE - All 6 models verified working
**Documentation**: `docs/LXC_DEPLOYMENT.md`

**Quick Access**:
```bash
# Health check
curl http://localhost:3000/health

# Test with Claude CLI
export ANTHROPIC_BASE_URL="http://localhost:3000"
claude --settings config/glm.json -p "Your query"
```

**Service Management** (on Proxmox host):
```bash
# Restart service
pct exec <container-id> -- systemctl restart anthropic-bridge

# View logs
pct exec <container-id> -- journalctl -u anthropic-bridge -f
```

### ğŸ³ Docker - WORKS WITH LIMITATIONS

**Status**: âœ… Container works internally, âš ï¸ Network access from host may have IPv6 issues on WSL2
**Documentation**: `docs/DOCKER_LXC_DEPLOYMENT.md`

**Deploy**:
```bash
docker-compose up -d
```

**Test from inside container**:
```bash
docker exec anthropic-bridge curl http://localhost:3000/health
```

### ğŸ’» Native - DEVELOPMENT

**Status**: âœ… All 6 models verified working

**Start**:
```bash
./scripts/start-anthropic-bridge.sh
```

Or manually:
```bash
cd smart-router
export OPENROUTER_API_KEY="your-key-here"
node src/anthropic-bridge.js
```

## ğŸ¯ Supported Models (6 Total)

All models verified working:

1. **GLM 4.6 Exacto** - `z-ai/glm-4.6:exacto`
2. **Deepseek Chat** - `deepseek/deepseek-chat`
3. **Qwen 2.5 Coder 32B** - `qwen/qwen-2.5-coder-32b-instruct`
4. **GPT-4o** - `openai/gpt-4o`
5. **Claude Sonnet 4** - `anthropic/claude-sonnet-4`
6. **Gemini 2.5 Pro** - `google/gemini-2.5-pro-preview`

## ğŸ“ Project Structure

```
smart-router/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ anthropic-bridge.js         # Main service (Anthropic to OpenAI translator)
â”œâ”€â”€ config/                          # Claude CLI configuration files
â”‚   â”œâ”€â”€ glm.json                    # GLM 4.6 Exacto
â”‚   â”œâ”€â”€ deepseek-v3.1-terminus.json # Deepseek Chat
â”‚   â”œâ”€â”€ qwen3-coder-plus.json       # Qwen 2.5 Coder 32B
â”‚   â”œâ”€â”€ gpt-5-pro.json              # GPT-4o
â”‚   â”œâ”€â”€ claude-sonnet-4.5.json      # Claude Sonnet 4
â”‚   â””â”€â”€ gemini-2.5-pro.json         # Gemini 2.5 Pro
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ start-anthropic-bridge.sh   # Native startup script
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ LXC_DEPLOYMENT.md           # LXC production deployment (RECOMMENDED)
â”‚   â”œâ”€â”€ DOCKER_LXC_DEPLOYMENT.md    # Docker deployment guide
â”‚   â””â”€â”€ CLI_TESTING.md              # Claude CLI testing guide
â”œâ”€â”€ .env                             # OpenRouter API key
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Environment Variables

**Required**:
- `OPENROUTER_API_KEY` - Your OpenRouter API key from https://openrouter.ai/

**Optional**:
- `PORT` - Server port (default: 3000)
- `NODE_ENV` - Environment (development/production)

### Claude CLI Configuration

Each model has a configuration file in `config/` directory:

```json
{
  "env": {
    "ANTHROPIC_BASE_URL": "http://localhost:3000",
    "ANTHROPIC_MODEL": "z-ai/glm-4.6:exacto"
  },
  "model": "z-ai/glm-4.6:exacto"
}
```

**Usage**:
```bash
# Use GLM 4.6
claude --settings config/glm.json -p "Your query"

# Use Deepseek
claude --settings config/deepseek-v3.1-terminus.json -p "Your query"

# Use Claude Sonnet 4
claude --settings config/claude-sonnet-4.5.json -p "Your query"
```

## ğŸ“Š Service Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     Anthropic      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     OpenAI       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Claude CLI  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ anthropic-bridge â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ OpenRouter â”‚
â”‚             â”‚   Format Request   â”‚ (Translation)     â”‚   Format Request â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Model Router â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                       â–¼                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ GLM â”‚               â”‚ Deepseek â”‚            â”‚ Claude   â”‚
                â”‚GPT-4â”‚               â”‚ Qwen     â”‚            â”‚ Gemini   â”‚
                â””â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ Monitoring

### Service Logs (LXC)
```bash
# Real-time logs
pct exec <container-id> -- journalctl -u anthropic-bridge -f

# Last 50 lines
pct exec <container-id> -- journalctl -u anthropic-bridge -n 50

# Follow routing activity
pct exec <container-id> -- journalctl -u anthropic-bridge -f | grep -E 'Forwarding|Response'
```

### Health Check
```bash
curl http://localhost:3000/health
```

Expected response:
```json
{
  "status": "healthy",
  "service": "Smart Router",
  "provider": "OpenRouter",
  "mode": "anthropic-to-openai-translator"
}
```

## ğŸ” Security

- API key stored in `.env` file (not committed to git)
- Service runs in isolated container
- Unprivileged container (non-root user namespace)
- Internal network only (no external exposure by default)

## ğŸ“ License

MIT

## ğŸ‘¤ Author

Marco Del Pin - marco.delpin@gmail.com

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

**Status**: âœ… PRODUCTION READY - All 6 models operational
**Last Updated**: 2025-11-06
